# -*- coding: utf-8 -*-
"""BREAST CANCERT DETECTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10LK0P_PZX6r5GNEsR-AjD4IkwwNePVWX
"""

import xgboost as xgb
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report,accuracy_score
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import roc_curve, roc_auc_score

# Dataset Load
data = load_breast_cancer()

# Convert the data into dataframe
df = pd.DataFrame(data.data,columns=data.feature_names)
df.head()

df['target']= data.target
#df table me ek naya column banao jiska naam target ho, aur usme data.target ki values daal do

df['target'].value_counts()

# Separated features and labels
X = df.drop('target',axis=1)   # x is feature and target is result so result sould not enter into feature otherwise model ko question wor answer dono mil jayega.
y = df['target']



#Split my df into training and testing data sets
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)

# XG boost model
model = xgb.XGBClassifier(n_estimators = 100,learning_rate=0.1,max_depth = 5,subsample = 0.8)

model.fit(X_train,y_train)

y_pred = model.predict(X_test)
# by default threshoild is 0.5

model.intercept_

# Accuracy chcek
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)
print(cm)

sns.heatmap(cm,annot=True)

"""ALUE-BY-VALUE EXPLANATION

ğŸ”¹ TN = 40

âœ”ï¸ 40 malignant cases sahi identify hue

ğŸ”¹ FP = 3

âš ï¸ 3 benign ko malignant bola

ğŸ‘‰ Extra test karwana padega (safe side)

ğŸ”¹ FN = 2 âŒâŒâŒ

ğŸš¨ 2 malignant ko benign bola

ğŸ‘‰ Most dangerous mistake

ğŸ”¹ TP = 69

âœ”ï¸ 69 benign cases sahi pakde

# â€œAlthough the model achieved 95.6% accuracy, I focused on recall for malignant cases. The confusion matrix shows only 2 false negatives, which is critical for medical diagnosis.â€

Reduce False Negatives

Change decision threshold

Improve recall
"""

# STEP 1: Use Probability Instead of Direct Predict

y_prob = model.predict_proba(X_test)[:, 1]

# changing threshold  from bydefault 0.5 to 0.4.
threshold = 0.4
y_pred_custom = (y_prob >= threshold).astype(int)

"""- Threshold â†‘ â†’ more precision, fewer false positives, but lower recall.

- Threshold â†“ â†’ more recall, fewer false negatives, but lower precision.

"""

#Reevaluate the model

print(confusion_matrix(y_test, y_pred_custom))
print(classification_report(y_test, y_pred_custom))

print(cm1)

cm1 = confusion_matrix(y_test, y_pred_custom)
sns.heatmap(cm1,annot= True)

"""WHAT IMPROVED?

ğŸ”¹ False Negatives (MOST IMPORTANT)

Old FN = 2

New FN = 1 âœ…

ğŸ‘‰ Tumne 1 extra cancer case detect kar liya
"""



fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc = roc_auc_score(y_test, y_prob)

plt.figure()
plt.plot(fpr, tpr, label=f"AUC = {auc:.3f}")
plt.plot([0,1], [0,1], linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate (Recall)")
plt.title("ROC Curve - Breast Cancer Detection")
plt.legend()
plt.show()

"""1ï¸âƒ£ What is this graph?

This graph shows:

How good your model is at separating cancer vs non-cancer

2ï¸âƒ£ X-axis (False Positive Rate)

ğŸ‘‰ How often the model raises false alarm

Low value = good

High value = bad

3ï¸âƒ£ Y-axis (True Positive Rate / Recall)

ğŸ‘‰ How many actual cancer cases the model correctly catches

High value = very good

This is what doctors care about

4ï¸âƒ£ Blue Curve

Your modelâ€™s performance

The closer it stays to the top-left corner, the better

ğŸ‘‰ Your curve goes almost straight up ğŸ”¥
That means:

It catches cancer cases early

With very few false alarms

5ï¸âƒ£ Orange Dashed Line

This is a random guess

Like flipping a coin ğŸ²

Your model is far above this line â†’ means itâ€™s actually learning.

ğŸ† MOST IMPORTANT NUMBER: AUC = 0.993
What does AUC mean?

â€œIf I randomly pick one cancer case and one non-cancer case,
the model will correctly rank them 99.3% of the time.â€

# The ROC curve shows that my model achieves a very high true positive rate with a low false positive rate. An AUC of 0.993 indicates excellent separability between malignant and benign tumors, making it suitable for medical screening
"""

# Featue importance
importance =pd.Series(model.feature_importances_,index = data.feature_names)

print(pd.Series(importance).sort_values(ascending = False).head())

"""- Feature importance shows which variables drive the modelâ€™s predictions. For example, in cancer detection dataset, mean concave points is the strongest signal, while worst radius contributes less.

"""































